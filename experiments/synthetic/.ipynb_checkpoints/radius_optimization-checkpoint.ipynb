{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda: True\n",
      "Cuda: True\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import gan\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Cuda: \" + str(cuda))\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model back and sample from it\n",
    "latent_dim = 2\n",
    "loaded_gen = gan.load_model(\"good_generator_2018_07_11\").eval()\n",
    "\n",
    "for param in loaded_gen.parameters():\n",
    "    param.requires_grad = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iteration 0]\n",
      "Flipping 20000.000000 to 19999.933594\n",
      "Regularized loss: 19999.933594\n",
      "[Iteration 1]\n",
      "Flipping 19999.933594 to 18894.875000\n",
      "Regularized loss: 18894.875000\n",
      "[Iteration 2]\n",
      "Flipping 18894.875000 to 6090.455078\n",
      "Regularized loss: 6090.455078\n",
      "[Iteration 3]\n",
      "Flipping 6090.455078 to 0.295794\n",
      "Regularized loss: 0.295794\n",
      "[Iteration 4]\n",
      "Regularized loss: 200.139694\n",
      "[Iteration 5]\n",
      "Regularized loss: 1220.866577\n",
      "[Iteration 6]\n",
      "Regularized loss: 232.304565\n",
      "[Iteration 7]\n",
      "Regularized loss: 0.358160\n",
      "[Iteration 8]\n",
      "Regularized loss: 0.330161\n",
      "[Iteration 9]\n",
      "Regularized loss: 0.315809\n",
      "[Iteration 10]\n",
      "Regularized loss: 0.308383\n",
      "[Iteration 11]\n",
      "Regularized loss: 0.304525\n",
      "[Iteration 12]\n",
      "Regularized loss: 0.302519\n",
      "[Iteration 13]\n",
      "Regularized loss: 0.301476\n",
      "[Iteration 14]\n",
      "Regularized loss: 0.300933\n",
      "[Iteration 15]\n",
      "Regularized loss: 0.300650\n",
      "[Iteration 16]\n",
      "Regularized loss: 0.300502\n",
      "[Iteration 17]\n",
      "Regularized loss: 0.300423\n",
      "[Iteration 18]\n",
      "Regularized loss: 0.300379\n",
      "[Iteration 19]\n",
      "Regularized loss: 0.300354\n",
      "[Iteration 20]\n",
      "Regularized loss: 0.300339\n",
      "[Iteration 21]\n",
      "Regularized loss: 0.300328\n",
      "[Iteration 22]\n",
      "Regularized loss: 0.300320\n",
      "[Iteration 23]\n",
      "Regularized loss: 0.300313\n",
      "[Iteration 24]\n",
      "Regularized loss: 0.300306\n",
      "[Iteration 25]\n",
      "Regularized loss: 0.300299\n",
      "[Iteration 26]\n",
      "Regularized loss: 0.300293\n",
      "[Iteration 27]\n",
      "Regularized loss: 0.300286\n",
      "[Iteration 28]\n",
      "Regularized loss: 0.300280\n",
      "[Iteration 29]\n",
      "Regularized loss: 0.300273\n",
      "[Iteration 30]\n",
      "Regularized loss: 0.300266\n",
      "[Iteration 31]\n",
      "Regularized loss: 0.300260\n",
      "[Iteration 32]\n",
      "Regularized loss: 0.300253\n",
      "[Iteration 33]\n",
      "Regularized loss: 0.300246\n",
      "[Iteration 34]\n",
      "Regularized loss: 0.300238\n",
      "[Iteration 35]\n",
      "Regularized loss: 0.300231\n",
      "[Iteration 36]\n",
      "Regularized loss: 0.300224\n",
      "[Iteration 37]\n",
      "Regularized loss: 0.300216\n",
      "[Iteration 38]\n",
      "Regularized loss: 0.300209\n",
      "[Iteration 39]\n",
      "Regularized loss: 0.300201\n",
      "[Iteration 40]\n",
      "Regularized loss: 0.300193\n",
      "[Iteration 41]\n",
      "Regularized loss: 0.300185\n",
      "[Iteration 42]\n",
      "Regularized loss: 0.300178\n",
      "[Iteration 43]\n",
      "Regularized loss: 0.300170\n",
      "[Iteration 44]\n",
      "Regularized loss: 0.300161\n",
      "[Iteration 45]\n",
      "Regularized loss: 0.300153\n",
      "[Iteration 46]\n",
      "Regularized loss: 0.300145\n",
      "[Iteration 47]\n",
      "Regularized loss: 0.300137\n",
      "[Iteration 48]\n",
      "Regularized loss: 0.300128\n",
      "[Iteration 49]\n",
      "Regularized loss: 0.300120\n",
      "[Iteration 50]\n",
      "Regularized loss: 0.300111\n",
      "[Iteration 51]\n",
      "Regularized loss: 0.300102\n",
      "[Iteration 52]\n",
      "Regularized loss: 0.300093\n",
      "[Iteration 53]\n",
      "Regularized loss: 0.300085\n",
      "[Iteration 54]\n",
      "Regularized loss: 0.300076\n",
      "[Iteration 55]\n",
      "Regularized loss: 0.300067\n",
      "[Iteration 56]\n",
      "Regularized loss: 0.300057\n",
      "[Iteration 57]\n",
      "Regularized loss: 0.300048\n",
      "[Iteration 58]\n",
      "Regularized loss: 0.300039\n",
      "[Iteration 59]\n",
      "Regularized loss: 0.300030\n",
      "[Iteration 60]\n",
      "Regularized loss: 0.300020\n",
      "[Iteration 61]\n",
      "Regularized loss: 0.300011\n",
      "[Iteration 62]\n",
      "Regularized loss: 0.300001\n",
      "[Iteration 63]\n",
      "Regularized loss: 0.299991\n",
      "[Iteration 64]\n",
      "Regularized loss: 0.299982\n",
      "[Iteration 65]\n",
      "Regularized loss: 0.299972\n",
      "[Iteration 66]\n",
      "Regularized loss: 0.299962\n",
      "[Iteration 67]\n",
      "Regularized loss: 0.299952\n",
      "[Iteration 68]\n",
      "Regularized loss: 0.299942\n",
      "[Iteration 69]\n",
      "Regularized loss: 0.299932\n",
      "[Iteration 70]\n",
      "Regularized loss: 0.299922\n",
      "[Iteration 71]\n",
      "Regularized loss: 0.299912\n",
      "[Iteration 72]\n",
      "Regularized loss: 0.299901\n",
      "[Iteration 73]\n",
      "Regularized loss: 0.299891\n",
      "[Iteration 74]\n",
      "Regularized loss: 0.299880\n",
      "[Iteration 75]\n",
      "Regularized loss: 0.299870\n",
      "[Iteration 76]\n",
      "Regularized loss: 0.299859\n",
      "[Iteration 77]\n",
      "Regularized loss: 0.299849\n",
      "[Iteration 78]\n",
      "Regularized loss: 0.299838\n",
      "[Iteration 79]\n",
      "Regularized loss: 0.299827\n",
      "[Iteration 80]\n",
      "Regularized loss: 0.299816\n",
      "[Iteration 81]\n",
      "Regularized loss: 0.299806\n",
      "[Iteration 82]\n",
      "Regularized loss: 0.299795\n",
      "[Iteration 83]\n",
      "Regularized loss: 0.299784\n",
      "[Iteration 84]\n",
      "Regularized loss: 0.299772\n",
      "[Iteration 85]\n",
      "Regularized loss: 0.299761\n",
      "[Iteration 86]\n",
      "Regularized loss: 0.299750\n",
      "[Iteration 87]\n",
      "Regularized loss: 0.299739\n",
      "[Iteration 88]\n",
      "Regularized loss: 0.299727\n",
      "[Iteration 89]\n",
      "Regularized loss: 0.299716\n",
      "[Iteration 90]\n",
      "Regularized loss: 0.299705\n",
      "[Iteration 91]\n",
      "Regularized loss: 0.299693\n",
      "[Iteration 92]\n",
      "Regularized loss: 0.299682\n",
      "[Iteration 93]\n",
      "Regularized loss: 0.299670\n",
      "[Iteration 94]\n",
      "Regularized loss: 0.299658\n",
      "[Iteration 95]\n",
      "Regularized loss: 0.299646\n",
      "[Iteration 96]\n",
      "Regularized loss: 0.299635\n",
      "[Iteration 97]\n",
      "Regularized loss: 0.299623\n",
      "[Iteration 98]\n",
      "Regularized loss: 0.299611\n",
      "[Iteration 99]\n",
      "Regularized loss: 0.299599\n",
      "[Iteration 100]\n",
      "Regularized loss: 0.299587\n",
      "[Iteration 101]\n",
      "Regularized loss: 0.299575\n",
      "[Iteration 102]\n",
      "Regularized loss: 0.299563\n",
      "[Iteration 103]\n",
      "Regularized loss: 0.299550\n",
      "[Iteration 104]\n",
      "Regularized loss: 0.299538\n",
      "[Iteration 105]\n",
      "Regularized loss: 0.299526\n",
      "[Iteration 106]\n",
      "Regularized loss: 0.299513\n",
      "[Iteration 107]\n",
      "Regularized loss: 0.299501\n",
      "[Iteration 108]\n",
      "Regularized loss: 0.299489\n",
      "[Iteration 109]\n",
      "Regularized loss: 0.299476\n",
      "[Iteration 110]\n",
      "Regularized loss: 0.299463\n",
      "[Iteration 111]\n",
      "Regularized loss: 0.299451\n",
      "[Iteration 112]\n",
      "Regularized loss: 0.299438\n",
      "[Iteration 113]\n",
      "Regularized loss: 0.299425\n",
      "[Iteration 114]\n",
      "Regularized loss: 0.299412\n",
      "[Iteration 115]\n",
      "Regularized loss: 0.299400\n",
      "[Iteration 116]\n",
      "Regularized loss: 0.299387\n",
      "[Iteration 117]\n",
      "Regularized loss: 0.299374\n",
      "[Iteration 118]\n",
      "Regularized loss: 0.299361\n",
      "[Iteration 119]\n",
      "Regularized loss: 0.299348\n",
      "[Iteration 120]\n",
      "Regularized loss: 0.299335\n",
      "[Iteration 121]\n",
      "Regularized loss: 0.299321\n",
      "[Iteration 122]\n",
      "Regularized loss: 0.299308\n",
      "[Iteration 123]\n",
      "Regularized loss: 0.299295\n",
      "[Iteration 124]\n",
      "Regularized loss: 0.299282\n",
      "[Iteration 125]\n",
      "Regularized loss: 0.299268\n",
      "[Iteration 126]\n",
      "Regularized loss: 0.299255\n",
      "[Iteration 127]\n",
      "Regularized loss: 0.299241\n",
      "[Iteration 128]\n",
      "Regularized loss: 0.299228\n",
      "[Iteration 129]\n",
      "Regularized loss: 0.299214\n",
      "[Iteration 130]\n",
      "Regularized loss: 0.299201\n",
      "[Iteration 131]\n",
      "Regularized loss: 0.299187\n",
      "[Iteration 132]\n",
      "Regularized loss: 0.299173\n",
      "[Iteration 133]\n",
      "Regularized loss: 0.299160\n",
      "[Iteration 134]\n",
      "Regularized loss: 0.299146\n",
      "[Iteration 135]\n",
      "Regularized loss: 0.299132\n",
      "[Iteration 136]\n",
      "Regularized loss: 0.299118\n",
      "[Iteration 137]\n",
      "Regularized loss: 0.299104\n",
      "[Iteration 138]\n",
      "Regularized loss: 0.299090\n",
      "[Iteration 139]\n",
      "Regularized loss: 0.299076\n",
      "[Iteration 140]\n",
      "Regularized loss: 0.299062\n",
      "[Iteration 141]\n",
      "Regularized loss: 0.299048\n",
      "[Iteration 142]\n",
      "Regularized loss: 0.299034\n",
      "[Iteration 143]\n",
      "Regularized loss: 0.299019\n",
      "[Iteration 144]\n",
      "Regularized loss: 0.299005\n",
      "[Iteration 145]\n",
      "Regularized loss: 0.298991\n",
      "[Iteration 146]\n",
      "Regularized loss: 0.298977\n",
      "[Iteration 147]\n",
      "Regularized loss: 0.298962\n",
      "[Iteration 148]\n",
      "Regularized loss: 0.298948\n",
      "[Iteration 149]\n",
      "Regularized loss: 0.298933\n",
      "[Iteration 150]\n",
      "Regularized loss: 0.298919\n",
      "[Iteration 151]\n",
      "Regularized loss: 0.298904\n",
      "[Iteration 152]\n",
      "Regularized loss: 0.298889\n",
      "[Iteration 153]\n",
      "Regularized loss: 0.298875\n",
      "[Iteration 154]\n",
      "Regularized loss: 0.298860\n",
      "[Iteration 155]\n",
      "Regularized loss: 0.298845\n",
      "[Iteration 156]\n",
      "Regularized loss: 0.298830\n",
      "[Iteration 157]\n",
      "Regularized loss: 0.298816\n",
      "[Iteration 158]\n",
      "Regularized loss: 0.298801\n",
      "[Iteration 159]\n",
      "Regularized loss: 0.298786\n",
      "[Iteration 160]\n",
      "Regularized loss: 0.298771\n",
      "[Iteration 161]\n",
      "Regularized loss: 0.298756\n",
      "[Iteration 162]\n",
      "Regularized loss: 0.298741\n",
      "[Iteration 163]\n",
      "Regularized loss: 0.298726\n",
      "[Iteration 164]\n",
      "Regularized loss: 0.298711\n",
      "[Iteration 165]\n",
      "Regularized loss: 0.298695\n",
      "[Iteration 166]\n",
      "Regularized loss: 0.298680\n",
      "[Iteration 167]\n",
      "Regularized loss: 0.298665\n",
      "[Iteration 168]\n",
      "Regularized loss: 0.298650\n",
      "[Iteration 169]\n",
      "Regularized loss: 0.298634\n",
      "[Iteration 170]\n",
      "Regularized loss: 0.298619\n",
      "[Iteration 171]\n",
      "Regularized loss: 0.298603\n",
      "[Iteration 172]\n",
      "Regularized loss: 0.298588\n",
      "[Iteration 173]\n",
      "Regularized loss: 0.298572\n",
      "[Iteration 174]\n",
      "Regularized loss: 0.298557\n",
      "[Iteration 175]\n",
      "Regularized loss: 0.298541\n",
      "[Iteration 176]\n",
      "Regularized loss: 0.298526\n",
      "[Iteration 177]\n",
      "Regularized loss: 0.298510\n",
      "[Iteration 178]\n",
      "Regularized loss: 0.298494\n",
      "[Iteration 179]\n",
      "Regularized loss: 0.298479\n",
      "[Iteration 180]\n",
      "Regularized loss: 0.298463\n",
      "[Iteration 181]\n",
      "Regularized loss: 0.298447\n",
      "[Iteration 182]\n",
      "Regularized loss: 0.298431\n",
      "[Iteration 183]\n",
      "Regularized loss: 0.298415\n",
      "[Iteration 184]\n",
      "Regularized loss: 0.298399\n",
      "[Iteration 185]\n",
      "Regularized loss: 0.298383\n",
      "[Iteration 186]\n",
      "Regularized loss: 0.298367\n",
      "[Iteration 187]\n",
      "Regularized loss: 0.298351\n",
      "[Iteration 188]\n",
      "Regularized loss: 0.298335\n",
      "[Iteration 189]\n",
      "Regularized loss: 0.298319\n",
      "[Iteration 190]\n",
      "Regularized loss: 0.298303\n",
      "[Iteration 191]\n",
      "Regularized loss: 0.298287\n",
      "[Iteration 192]\n",
      "Regularized loss: 0.298270\n",
      "[Iteration 193]\n",
      "Regularized loss: 0.298254\n",
      "[Iteration 194]\n",
      "Regularized loss: 0.298238\n",
      "[Iteration 195]\n",
      "Regularized loss: 0.298221\n",
      "[Iteration 196]\n",
      "Regularized loss: 0.298205\n",
      "[Iteration 197]\n",
      "Regularized loss: 0.298189\n",
      "[Iteration 198]\n",
      "Regularized loss: 0.298172\n",
      "[Iteration 199]\n",
      "Regularized loss: 0.298156\n"
     ]
    }
   ],
   "source": [
    "z = Variable(Tensor(np.random.normal(0, 1, (1, latent_dim))), requires_grad=False)\n",
    "r = gan.dist_to_boundary(loaded_gen, z, latent_dim=latent_dim, lr=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4090, device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.class_radius_loss(loaded_gen, z, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
